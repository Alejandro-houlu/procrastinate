{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import torch\n",
    "from transformers import AutoModelForSpeechSeq2Seq, AutoProcessor, pipeline\n",
    "import scipy\n",
    "from datasets import load_dataset\n",
    "from pydub import AudioSegment\n",
    "import librosa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "General Workflow:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "1. Speech signal ---> Text\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "2. Text ----> Dirichlet Clusters\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "3. Dirichlet Cluster keywords ---> Search Engine / Youtube API\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Due to a bug fix in https://github.com/huggingface/transformers/pull/28687 transcription using a multilingual Whisper will default to language detection followed by transcription instead of translation to English.This might be a breaking change for your use case. If you want to instead always translate your audio to English, make sure to pass `language='en'`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Mr. Quilter is the apostle of the middle classes, and we are glad to welcome his gospel. Nor is Mr. Quilter's manner less interesting than his matter. He tells us that at this festive season of the year, with Christmas and roast beef looming before us, similes drawn from eating and its results occur most readily to the mind. He has grave doubts whether Sir Frederick Leighton's work is really Greek after all, and can discover in it but little of rocky Ithaca. Linnell's pictures are a sort of Upguards and Adam paintings, and Mason's exquisite idylls are as national as a jingo poem. Mr. Burkett Foster's landscapes smile at one much in the same way that Mr. Carker used to flash his teeth. And Mr. John Collier gives his sitter a cheerful slap on the back before he says, like a shampooer in a Turkish bath, Next man!\n"
     ]
    }
   ],
   "source": [
    "### Loading model to device\n",
    "\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "torch_dtype = torch.float16 if torch.cuda.is_available() else torch.float32\n",
    "\n",
    "model_id = \"openai/whisper-large-v3\"\n",
    "\n",
    "model = AutoModelForSpeechSeq2Seq.from_pretrained(\n",
    "    model_id, torch_dtype=torch_dtype, low_cpu_mem_usage=True, use_safetensors=True\n",
    ")\n",
    "model.to(device)\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(model_id)\n",
    "\n",
    "pipe = pipeline(\n",
    "    \"automatic-speech-recognition\",\n",
    "    model=model,\n",
    "    tokenizer=processor.tokenizer,\n",
    "    feature_extractor=processor.feature_extractor,\n",
    "    max_new_tokens=128,\n",
    "    chunk_length_s=30,\n",
    "    batch_size=16,\n",
    "    return_timestamps=True,\n",
    "    torch_dtype=torch_dtype,\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "dataset = load_dataset(\"distil-whisper/librispeech_long\", \"clean\", split=\"validation\")\n",
    "sample = dataset[0][\"audio\"]\n",
    "\n",
    "result = pipe(sample)\n",
    "print(result[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_audio_path = \"cmu_computer_graphics_course_admin_recording.mp3\"\n",
    "# audio = scipy.io.wavfile.read(mono_audio_path)[1]\n",
    "# print(audio)\n",
    "# print(audio.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We use the librosa package here to read mp3 files, for more information regarding the librosa package, you can visit: https://github.com/librosa/librosa\n",
    "Note: Librosa works for mp3, m4a files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.9852335e-22 8.2718061e-24 1.9852335e-23 ... 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00]\n",
      "22050\n"
     ]
    }
   ],
   "source": [
    "y, sr = librosa.load(sample_audio_path)\n",
    "print(y)\n",
    "print(sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Welcome to Computer Graphics 15462-662 at Carnegie Mellon University. I'm Kenan Crane. I'm a professor of computer science and robotics. And I also do research in computer graphics, so specifically in the area of geometric algorithms. The purpose of this video is to give you all the information that you'll need to succeed this semester. So periodically we'll upload little videos to cover administrative things, to talk about what's been going on this week, and to answer any significant questions that have come up. I should also say that all the information today is available on the course webpage at 15462.courses.cs.cmu.edu. So please go ahead, check out that link, read through especially the course info page in detail because there's a lot of things that I won't say here in this video but that are important for you to know as you go through the course. we have a great set of TAs this semester. So if you have any questions, please at any time, feel free to email them, email me, post a question on Piazza, whatever you like to do, but don't be shy about getting in touch. The first things you should do to get running with the course is to sign up for Piazza. So go to piazza.com slash CMU, find our course 462 and sign up. And second, to sign up for an account on the course webpage. Click on the login button in the upper right and you should see a link that says sign up to sign up you will need a special passcode which is available only on Piazza so you'd better sign up for Piazza first before you sign up for the course webpage I should also say if you're not officially enrolled in this course yet, don't worry. First of all, usually there's no trouble getting in. We don't really have much of a class size limitation this semester. Just sign up for the webpage, get rolling, start reading through the assignments and so forth, so that if you do decide to add the course you're on track. So we will be running the whole course remotely and it basically has three components. We have lectures, we have recitations, and we have office hours which will all be done online. The recitations and the office hours will be done through Zoom, and you'll be able to find the appropriate Zoom links on Piazza. The lectures will be pre-recorded videos that you can watch on YouTube, but we will be there during the lecture period to answer questions that might come up while you watch these videos. So if you're watching the video, something doesn't make sense, just hit pause, go to the Zoom room, talk to us, ask us questions, and then go back to your video. A couple of tips, it can be really hard, I know, when you're sitting at home to pay attention to a long 80-minute lecture video. So a couple of things that our students have found are useful. One is to simply speed up the video, which you can do using YouTube. So if you've never done that before, you can give that a try right now. Go to the bottom right, you should see a little gear icon and you'll see a little option for playback speed so you can speed up the video as fast as you can as fast as you can take it the other thing that can be very helpful is to just break up watching the video into chunks so if it's 80 minutes long, maybe you break it up into 40 minutes today and 40 minutes tomorrow. That can really help to keep focused. In terms of work that you'll have to do for this course, they're really just three main things. There are many homeworks. So this is just two or three questions that we're going to ask after each lecture to just make sure that you understand what's going on then there's four major coding assignments so over the course of the semester you're going to build up a 3d package called scotty 3d and scotty 3d is just like any modern 3d package it has modeling it has rendering it has animation but the difference is all of the key routines have been stripped out and you're gonna go ahead and fill them in and hopefully be able to create some really cool content, really cool models and animations. And finally, we will have a midterm and a final, but please do not sweat about this. Each of these is worth only 10% of your grade. This is mainly just a checkpoint to make sure that you understand conceptually what's going on in the course, not just the coding. Also, please be aware that you have five late days, which you can use completely at your discretion. You don't have to ask us, can I use it for this or that? Just go ahead and use it. In terms of collaboration, we encourage people to talk to their peers, to have interesting conversations on Piazza, to come to office hours and ask whatever you like, but your final work must be your own. All assignments in this class will be individual work. All the details, again, you can find on the webpage about collaboration and cheating and so forth. Okay, that's it. So if you have questions, please don't hesitate to reach out and contact us on Piazza, on email, whatever you like. Otherwise, if you're excited about getting rolling, you can start watching the first lecture right away. So just go to the course webpage, you'll see our course schedule, and you can just click on the video links to get started. So that's it. Looking forward to seeing you this semester.\n"
     ]
    }
   ],
   "source": [
    "output_result = pipe(y, generate_kwargs={\"language\": \"english\", \"task\": \"transcribe\"})\n",
    "print(output_result[\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exporting the transcribed voice into a text file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = \"cmu_computer_graphics_intro_voice_transcribed.txt\"\n",
    "transcribed_text = output_result[\"text\"]\n",
    "with open(output_file, \"w\") as dst:\n",
    "    dst.write(transcribed_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "procrastinate",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
